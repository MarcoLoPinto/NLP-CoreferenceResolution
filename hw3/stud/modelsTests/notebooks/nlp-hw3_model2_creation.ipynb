{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fe2040e",
   "metadata": {
    "papermill": {
     "duration": 0.078963,
     "end_time": "2022-03-31T22:14:09.386664",
     "exception": false,
     "start_time": "2022-03-31T22:14:09.307701",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marco/miniconda3/envs/nlp2022-hw3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5424a631",
   "metadata": {
    "papermill": {
     "duration": 0.049244,
     "end_time": "2022-03-31T22:14:12.552634",
     "exception": false,
     "start_time": "2022-03-31T22:14:12.503390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Important paths for the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_root = '../../../../'\n",
    "test_name = 'test2'\n",
    "datasets_path = os.path.join(app_root, 'data')\n",
    "model_dir_path = os.path.join(app_root, 'model', test_name)\n",
    "\n",
    "data_train_path = os.path.join(datasets_path, 'conllpp_train.txt')\n",
    "data_dev_path = os.path.join(datasets_path, 'conllpp_dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append('../../../')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bc95ee",
   "metadata": {
    "papermill": {
     "duration": 0.048851,
     "end_time": "2022-03-31T22:14:13.015246",
     "exception": false,
     "start_time": "2022-03-31T22:14:12.966395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Setting the seed for reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 28\n",
    "\n",
    "# random.seed(SEED) # not used\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_params = {\n",
    "    'batch_size': 32,\n",
    "    'PAD_TOKEN': '<pad>',\n",
    "    'UNK_TOKEN': '<unk>',\n",
    "    'transformer_name': \"bert-base-cased\",\n",
    "    'mention_tags': {\n",
    "        'p_open':  '<P>', 'p_close':  '</P>', \n",
    "        'e_open':  '<E>', 'e_close':  '</E>', \n",
    "    },\n",
    "    'ner_pad_id': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9214a0",
   "metadata": {
    "papermill": {
     "duration": 0.049393,
     "end_time": "2022-03-31T22:14:13.226777",
     "exception": false,
     "start_time": "2022-03-31T22:14:13.177384",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stud.modelsTests.dataset.NERDataset_transformer_simple import NERDataset_transformer_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = NERDataset_transformer_simple(\n",
    "    data_train_path, \n",
    "    tokenizer = global_params['transformer_name'])\n",
    "\n",
    "dataset_dev = NERDataset_transformer_simple(\n",
    "    data_dev_path, \n",
    "    tokenizer = global_params['transformer_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_params.update({ \n",
    "    'token_embeddings_len': len(dataset_train.tokenizer),\n",
    "    'resize_token_embeddings': False, # ! not used\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(model_dir_path, 'global_params.npy'), global_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=global_params['batch_size'],\n",
    "    collate_fn=dataset_train.create_collate_fn(),\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "dataloader_dev = DataLoader(\n",
    "    dataset_dev,\n",
    "    batch_size=global_params['batch_size'],\n",
    "    collate_fn=dataset_dev.create_collate_fn(),\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in dataloader_dev:\n",
    "    ex_in = e\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'ner_tags', 'ner_tags_formatted', 'output_mask'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_in.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  101,  1537,  1890,  1155,   118,  1668,  1200,  5676, 14068,  1261,\n",
      "         1300,  1111,  3383,  1113,  5286,  1112, 21854,  3222,  8860,  1118,\n",
      "         1126,  6687,  1105,  3614,  2326,  1107,  1160,  1552,  1106,  1321,\n",
      "         1166,  1120,  1103,  1246,  1104,  1103,  2514,  2899,   119,   102,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0]) torch.Size([32, 52])\n",
      "tensor([-1,  0,  0,  0, -1, -1, -1,  1,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]) torch.Size([32, 52])\n",
      "[0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 52\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "print(ex_in['input_ids'][idx], ex_in['input_ids'].shape)\n",
    "print(ex_in['ner_tags_formatted'][idx], ex_in['ner_tags_formatted'].shape)\n",
    "print(ex_in['output_mask'][idx], len(ex_in['output_mask'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stud.modelsTests.utils.print_infos import print_summary, display_history, plot_confusion_matrix, print_classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from stud.modelsTests.model_2.model2_transformer_simple_multilogits import Model2\n",
    "import torch.optim as optim\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss(ignore_index = global_params['ner_pad_id']) # !\n",
    "\n",
    "final_model = Model2(\n",
    "    device = device,\n",
    "    loss_fn = loss_function,\n",
    "    model_load_weights = False,\n",
    "    fine_tune_transformer = True,\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(final_model.model.parameters(), lr=0.0016, momentum=0.9)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_some = False\n",
    "if freeze_some:\n",
    "    unfreeze_word_embeddings = False\n",
    "    unfreeze_transformer_layers = True\n",
    "    unfreeze_from_layer_num = 8\n",
    "    unfreeze_to_layer_num = 99\n",
    "    unfreeze_pooler = True\n",
    "\n",
    "    for name, param in final_model.model.named_parameters():\n",
    "\n",
    "        if name.startswith('transformer_model.embeddings'):\n",
    "            param.requires_grad = unfreeze_word_embeddings\n",
    "\n",
    "        elif name.startswith('transformer_model.encoder.layer'):\n",
    "            layer_num = int(name.split('.')[3])\n",
    "            if layer_num >= unfreeze_from_layer_num and layer_num <= unfreeze_to_layer_num:\n",
    "                param.requires_grad = unfreeze_transformer_layers\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        elif name.startswith('transformer_model.pooler'):\n",
    "            param.requires_grad = unfreeze_pooler\n",
    "        \n",
    "        print(param.requires_grad, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model2_net(\n",
      "  (transformer_model): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
      "  (loss_fn): CrossEntropyLoss()\n",
      ")\n",
      "----------------------\n",
      "parameters: 108,312,579\n",
      "trainable parameters: 108,312,579\n",
      "non-trainable parameters: 0\n"
     ]
    }
   ],
   "source": [
    "print_summary(final_model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1,  0,  0,  0, -1, -1, -1,  1,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0, -1, -1, -1, -1, -1],\n",
      "        [-1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0, -1,  1,  2,\n",
      "         -1, -1,  0,  0,  0,  0,  0, -1],\n",
      "        [-1,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         -1, -1, -1, -1, -1, -1, -1, -1]], device='cuda:0')\n",
      "tensor([[[ 1.8330e+00,  4.0506e+00,  1.6984e-02],\n",
      "         [ 9.1035e-01,  2.1046e+00,  1.4006e+00],\n",
      "         [ 1.7321e+00,  3.3197e+00,  1.3700e+00],\n",
      "         [ 1.8014e+00,  3.7505e+00,  1.6381e+00],\n",
      "         [ 1.4668e+00,  1.0048e+00, -8.2803e-02],\n",
      "         [ 2.1253e+00,  2.4539e+00,  3.9409e-01],\n",
      "         [ 1.0251e-01,  3.4384e+00,  1.9952e+00],\n",
      "         [ 1.5809e-01,  2.5996e+00, -5.3322e-01],\n",
      "         [ 2.0988e+00,  2.1767e+00, -7.2919e-01],\n",
      "         [ 8.2801e-01,  3.3268e+00,  5.9636e-01],\n",
      "         [ 4.0865e+00,  3.6126e+00, -1.5924e+00],\n",
      "         [ 1.3989e+00,  3.2790e+00, -7.3170e-01],\n",
      "         [ 3.1990e+00,  2.3460e+00, -6.5172e-01],\n",
      "         [ 1.4634e+00,  2.3145e+00,  1.0977e+00],\n",
      "         [ 1.8984e+00,  1.5890e+00, -2.5718e+00],\n",
      "         [-2.2779e+00,  9.0717e-01,  3.5060e+00],\n",
      "         [-1.6459e-01,  1.1073e+00, -1.0580e+00],\n",
      "         [ 5.3760e-01,  3.0569e+00,  4.7708e-01],\n",
      "         [ 7.4809e-01,  2.3217e+00, -5.4467e-01],\n",
      "         [-1.7710e-02,  4.1214e+00, -1.2769e+00],\n",
      "         [ 1.0937e+00,  2.9016e+00,  1.8342e-01],\n",
      "         [ 2.0616e+00,  4.4096e+00, -4.3609e-02],\n",
      "         [ 1.9516e+00,  3.1787e+00,  1.0102e-01],\n",
      "         [ 2.8052e+00,  3.6760e+00, -4.1415e-01],\n",
      "         [ 7.2352e-01,  2.9235e+00,  2.2069e-01],\n",
      "         [ 8.4923e-01,  2.3725e+00, -9.5973e-01],\n",
      "         [ 1.4477e+00,  2.9495e+00,  1.4736e+00],\n",
      "         [ 2.0572e+00,  2.7828e+00, -1.6769e+00],\n",
      "         [ 8.8898e-01,  1.6059e+00,  1.7676e+00],\n",
      "         [ 7.7758e-01,  1.5514e+00,  1.9118e+00],\n",
      "         [ 1.5190e+00,  6.6801e-01,  2.3279e+00],\n",
      "         [ 1.5872e+00, -2.1801e-01,  1.2731e+00],\n",
      "         [ 1.7730e+00,  7.6974e-01,  2.5891e+00],\n",
      "         [ 1.9742e+00, -6.5728e-01,  4.0967e+00],\n",
      "         [ 2.5819e+00,  8.3486e-01,  2.2917e+00],\n",
      "         [ 1.9651e+00,  2.1469e+00,  2.0226e+00],\n",
      "         [ 1.9212e+00,  1.3732e+00, -7.9144e-01],\n",
      "         [ 1.6978e+00,  5.2728e-01,  1.5890e+00],\n",
      "         [-5.2301e-03,  1.2704e+00, -8.3795e-01],\n",
      "         [-1.6883e-01,  1.1977e+00, -9.0721e-01],\n",
      "         [ 2.1140e+00,  2.6812e+00,  2.3158e+00],\n",
      "         [ 2.0492e+00,  2.5131e+00,  2.3491e+00],\n",
      "         [ 1.8272e+00,  2.3603e+00,  2.6120e+00],\n",
      "         [ 2.4809e+00,  2.7515e+00,  2.4031e+00]],\n",
      "\n",
      "        [[ 2.7413e+00,  4.5985e+00,  3.4381e-02],\n",
      "         [ 8.1214e-01,  1.6539e+00,  5.7696e-01],\n",
      "         [ 1.7944e+00,  5.1603e+00, -3.6260e-01],\n",
      "         [ 5.9175e-01,  2.6634e+00,  3.7476e-01],\n",
      "         [ 1.9262e+00,  2.1808e+00, -3.1680e-01],\n",
      "         [ 1.0555e+00,  3.8898e+00,  4.7508e-01],\n",
      "         [ 2.2857e+00,  2.9876e+00,  4.0880e-01],\n",
      "         [ 1.3906e+00,  2.6729e+00,  1.5968e+00],\n",
      "         [ 1.2579e+00,  4.0697e+00,  1.6123e+00],\n",
      "         [ 4.6991e+00,  1.3421e+00,  3.1300e+00],\n",
      "         [ 2.7730e+00,  3.2972e+00, -1.2512e+00],\n",
      "         [ 9.0985e-01,  4.4151e+00, -4.4273e-01],\n",
      "         [ 3.5514e+00,  1.6692e+00, -3.6411e-01],\n",
      "         [ 3.5434e-02,  3.2363e+00, -3.2903e-01],\n",
      "         [ 1.4042e+00,  2.7822e+00,  4.5039e+00],\n",
      "         [-6.6979e-02,  1.7445e+00, -1.2674e+00],\n",
      "         [ 1.2862e+00,  3.0342e+00,  2.4571e+00],\n",
      "         [-1.1060e+00,  2.9314e+00, -9.1157e-01],\n",
      "         [ 1.6777e+00,  2.3573e-01,  1.3852e+00],\n",
      "         [ 1.0410e+00,  4.7013e+00, -1.2503e+00],\n",
      "         [-1.5864e-03,  5.1469e+00, -5.0700e-01],\n",
      "         [ 8.5538e-01,  3.3460e+00,  2.1929e+00],\n",
      "         [-2.3343e-01,  4.0031e+00, -3.0821e-01],\n",
      "         [-6.3443e-01,  1.0179e+00,  1.3969e+00],\n",
      "         [ 1.4332e+00,  2.2475e+00,  1.8879e+00],\n",
      "         [ 1.9836e+00,  4.1393e+00, -2.1805e+00],\n",
      "         [ 1.6601e+00,  2.0328e+00, -7.5882e-01],\n",
      "         [ 4.3392e-01,  2.5902e+00,  3.1229e-01],\n",
      "         [ 2.6911e+00,  3.5959e+00, -1.3623e+00],\n",
      "         [ 2.2460e+00,  2.5450e+00,  6.1118e-01],\n",
      "         [ 1.4497e+00,  3.6138e+00,  3.1568e+00],\n",
      "         [ 4.6343e-01,  2.5142e+00,  2.0475e+00],\n",
      "         [ 2.9633e+00,  4.7493e+00, -5.3387e-01],\n",
      "         [ 1.3861e+00,  3.0734e+00,  1.7877e+00],\n",
      "         [ 4.4820e-01,  1.8624e+00, -8.4164e-01],\n",
      "         [ 2.7061e+00,  3.2001e+00,  5.0878e-01],\n",
      "         [-2.3197e+00,  1.8640e+00,  2.5340e-01],\n",
      "         [ 1.5068e+00,  1.9327e+00, -2.2048e-01],\n",
      "         [ 5.8461e-01,  2.5141e+00,  8.4971e-01],\n",
      "         [ 4.1284e+00,  3.4941e+00, -1.1678e+00],\n",
      "         [ 1.0772e+00,  3.2991e+00,  7.2492e-01],\n",
      "         [ 2.5650e+00,  3.1862e+00,  1.1029e+00],\n",
      "         [ 3.2116e-01,  1.6362e+00, -7.3116e-01],\n",
      "         [-2.3802e-03,  1.3544e+00, -8.5325e-01]],\n",
      "\n",
      "        [[ 1.5808e+00,  4.1747e+00,  1.5281e-01],\n",
      "         [ 1.1425e-01,  1.4546e+00,  1.8654e+00],\n",
      "         [ 9.1585e-01,  2.5077e+00,  1.5837e+00],\n",
      "         [ 8.2163e-01,  3.0812e+00,  1.2001e-02],\n",
      "         [ 1.4107e+00,  3.2995e+00, -5.6647e-01],\n",
      "         [ 1.3993e+00,  2.1748e+00,  3.4172e+00],\n",
      "         [ 1.2341e-01,  3.0537e+00,  6.6219e-01],\n",
      "         [ 8.2189e-01,  2.3574e+00,  2.3410e+00],\n",
      "         [ 2.4582e+00,  2.8017e+00,  1.1488e+00],\n",
      "         [ 3.2606e+00,  3.4692e+00,  1.4009e+00],\n",
      "         [ 1.8429e+00, -2.3911e-01,  1.2966e+00],\n",
      "         [ 2.9728e+00,  2.0844e+00,  3.4374e-01],\n",
      "         [-7.8892e-02,  2.3942e+00, -9.1846e-03],\n",
      "         [ 2.6408e+00,  1.3201e+00,  1.0467e+00],\n",
      "         [ 5.7432e-01,  3.8225e+00, -7.3532e-01],\n",
      "         [ 4.0372e-01,  1.3334e+00,  3.3293e+00],\n",
      "         [ 1.4707e+00,  3.2446e+00,  6.9655e-02],\n",
      "         [ 9.2374e-01,  3.5637e+00,  2.5342e+00],\n",
      "         [ 2.6744e+00,  3.5668e+00,  1.9342e+00],\n",
      "         [ 4.8544e-01,  4.4563e+00,  6.2774e-01],\n",
      "         [ 1.9623e+00,  3.2486e+00,  3.7365e-01],\n",
      "         [ 6.5728e-01,  3.3425e+00, -9.0309e-01],\n",
      "         [ 1.2837e+00,  1.5300e+00,  2.0149e-01],\n",
      "         [ 5.2766e-01,  3.3023e+00,  1.2606e+00],\n",
      "         [ 1.8639e+00,  3.7768e+00,  1.0339e+00],\n",
      "         [ 4.4087e-01,  1.6304e+00, -6.6850e-01],\n",
      "         [ 1.1616e-01,  1.2996e+00, -8.8387e-01],\n",
      "         [ 2.2357e+00,  1.8399e+00,  2.3621e+00],\n",
      "         [ 2.1007e+00,  2.4001e+00,  1.8924e+00],\n",
      "         [ 2.6304e+00,  2.7927e+00,  1.7447e+00],\n",
      "         [ 2.0390e+00,  2.4171e+00,  1.7087e+00],\n",
      "         [ 2.3464e+00,  1.8927e+00,  1.6849e+00],\n",
      "         [ 1.6174e+00,  2.8988e+00,  1.0213e+00],\n",
      "         [ 1.6938e+00,  2.8397e+00,  1.4197e+00],\n",
      "         [ 2.0773e+00,  1.7038e+00,  1.2071e+00],\n",
      "         [ 1.7493e+00,  2.3474e+00,  4.1070e-01],\n",
      "         [ 8.7680e-01,  3.8044e+00,  2.3691e+00],\n",
      "         [ 8.1415e-01,  3.8320e+00,  2.9676e+00],\n",
      "         [ 9.0449e-01,  3.1871e+00,  1.1589e+00],\n",
      "         [ 1.8925e+00,  3.8802e+00,  1.2378e+00],\n",
      "         [ 2.6057e+00,  3.8477e+00,  7.1422e-01],\n",
      "         [ 2.9033e+00,  3.3972e+00,  1.8639e+00],\n",
      "         [ 1.7114e+00,  2.4069e+00,  2.4042e+00],\n",
      "         [ 2.8189e+00,  1.5523e+00,  1.7068e+00]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(1.9714, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "ex_in_simple = dataset_dev.create_collate_fn()([dataset_dev[0], dataset_dev[1], dataset_dev[2]])\n",
    "predictions = final_model.model(\n",
    "    input_ids = ex_in_simple['input_ids'].to(device), \n",
    "    attention_mask = ex_in_simple['attention_mask'].to(device),\n",
    "    token_type_ids = ex_in_simple['token_type_ids'].to(device),\n",
    ")\n",
    "labels = ex_in_simple['ner_tags_formatted'].to(device)\n",
    "\n",
    "predictions_flattened = predictions.reshape(-1, predictions.shape[-1]) \n",
    "labels_flattened = labels.view(-1)\n",
    "\n",
    "predictions_flattened = predictions_flattened.to(device)\n",
    "labels_flattened = labels_flattened.to(device)\n",
    "\n",
    "print(labels)\n",
    "print(predictions)\n",
    "print(final_model.model.compute_loss(predictions_flattened, labels_flattened))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] 35 ['B', 'B', 'B', 'B', 'B', 'B', 'O', 'B', 'O', 'B', 'O', 'I', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'I', 'I', 'I', 'O', 'I', 'I', 'O', 'B', 'O', 'O', 'B'] 35\n"
     ]
    }
   ],
   "source": [
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "idsd = 0\n",
    "lab = dataset_dev.data_raw[idsd]['ner_tags']\n",
    "pred = final_model.predict(dataset_dev.data_raw[idsd])\n",
    "print(lab, len(lab), pred['ner'], len(pred['ner']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 => avg_loss: 0.813991\n",
      "#                   Validation loss => 0.103977 | f1: 0.656716 #\n",
      "Epoch   1 => avg_loss: 0.097853\n",
      "#                   Validation loss => 0.050672 | f1: 0.902439 #\n",
      "Epoch   2 => avg_loss: 0.047773\n",
      "#                   Validation loss => 0.040484 | f1: 0.945899 #\n",
      "Epoch   3 => avg_loss: 0.044939\n",
      "#                   Validation loss => 0.026888 | f1: 0.952043 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch   4 => avg_loss: 0.029127\n",
      "#                   Validation loss => 0.022438 | f1: 0.956370 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch   5 => avg_loss: 0.015099\n",
      "#                   Validation loss => 0.022444 | f1: 0.960000 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch   6 => avg_loss: 0.010702\n",
      "#                   Validation loss => 0.023033 | f1: 0.963351 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch   7 => avg_loss: 0.009398\n",
      "#                   Validation loss => 0.020823 | f1: 0.963093 #\n",
      "Epoch   8 => avg_loss: 0.007721\n",
      "#                   Validation loss => 0.019004 | f1: 0.964912 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch   9 => avg_loss: 0.006364\n",
      "#                   Validation loss => 0.019126 | f1: 0.963351 #\n",
      "Epoch  10 => avg_loss: 0.005300\n",
      "#                   Validation loss => 0.019055 | f1: 0.961538 #\n",
      "Epoch  11 => avg_loss: 0.004766\n",
      "#                   Validation loss => 0.018035 | f1: 0.963222 #\n",
      "Epoch  12 => avg_loss: 0.004317\n",
      "#                   Validation loss => 0.017448 | f1: 0.963222 #\n",
      "Epoch  13 => avg_loss: 0.003772\n",
      "#                   Validation loss => 0.017066 | f1: 0.964912 #\n",
      "Epoch  14 => avg_loss: 0.005621\n",
      "#                   Validation loss => 0.016890 | f1: 0.964912 #\n",
      "Epoch  15 => avg_loss: 0.004112\n",
      "#                   Validation loss => 0.017047 | f1: 0.961538 #\n",
      "Epoch  16 => avg_loss: 0.003410\n",
      "#                   Validation loss => 0.017184 | f1: 0.964912 #\n",
      "Epoch  17 => avg_loss: 0.002718\n",
      "#                   Validation loss => 0.016828 | f1: 0.964912 #\n",
      "Epoch  18 => avg_loss: 0.002672\n",
      "#                   Validation loss => 0.017412 | f1: 0.964912 #\n",
      "Epoch  19 => avg_loss: 0.002651\n",
      "#                   Validation loss => 0.017248 | f1: 0.966608 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch  20 => avg_loss: 0.002704\n",
      "#                   Validation loss => 0.017035 | f1: 0.964912 #\n",
      "Epoch  21 => avg_loss: 0.002007\n",
      "#                   Validation loss => 0.017718 | f1: 0.963222 #\n",
      "Epoch  22 => avg_loss: 0.001797\n",
      "#                   Validation loss => 0.018047 | f1: 0.963222 #\n",
      "Epoch  23 => avg_loss: 0.001938\n",
      "#                   Validation loss => 0.018258 | f1: 0.963222 #\n",
      "Epoch  24 => avg_loss: 0.001759\n",
      "#                   Validation loss => 0.018657 | f1: 0.966608 #\n",
      "Epoch  25 => avg_loss: 0.001612\n",
      "#                   Validation loss => 0.018737 | f1: 0.966608 #\n",
      "Epoch  26 => avg_loss: 0.001478\n",
      "#                   Validation loss => 0.018610 | f1: 0.966608 #\n",
      "Epoch  27 => avg_loss: 0.001357\n",
      "#                   Validation loss => 0.018384 | f1: 0.966608 #\n",
      "Epoch  28 => avg_loss: 0.001473\n",
      "#                   Validation loss => 0.017661 | f1: 0.968310 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch  29 => avg_loss: 0.001549\n",
      "#                   Validation loss => 0.018109 | f1: 0.968310 #\n",
      "Epoch  30 => avg_loss: 0.001366\n",
      "#                   Validation loss => 0.018319 | f1: 0.964912 #\n",
      "Epoch  31 => avg_loss: 0.001716\n",
      "#                   Validation loss => 0.018029 | f1: 0.964912 #\n",
      "Epoch  32 => avg_loss: 0.001625\n",
      "#                   Validation loss => 0.017363 | f1: 0.968310 #\n",
      "Epoch  33 => avg_loss: 0.001979\n",
      "#                   Validation loss => 0.017666 | f1: 0.968310 #\n",
      "Epoch  34 => avg_loss: 0.000910\n",
      "#                   Validation loss => 0.019657 | f1: 0.968421 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch  35 => avg_loss: 0.000852\n",
      "#                   Validation loss => 0.019886 | f1: 0.968421 #\n",
      "Epoch  36 => avg_loss: 0.000966\n",
      "#                   Validation loss => 0.019283 | f1: 0.966608 #\n",
      "Epoch  37 => avg_loss: 0.000729\n",
      "#                   Validation loss => 0.018931 | f1: 0.968310 #\n",
      "Epoch  38 => avg_loss: 0.000953\n",
      "#                   Validation loss => 0.018559 | f1: 0.968310 #\n",
      "Epoch  39 => avg_loss: 0.001391\n",
      "#                   Validation loss => 0.018136 | f1: 0.968310 #\n",
      "Epoch  40 => avg_loss: 0.000783\n",
      "#                   Validation loss => 0.017936 | f1: 0.968310 #\n",
      "Epoch  41 => avg_loss: 0.001213\n",
      "#                   Validation loss => 0.018123 | f1: 0.968310 #\n",
      "Epoch  42 => avg_loss: 0.000691\n",
      "#                   Validation loss => 0.018228 | f1: 0.968310 #\n",
      "Epoch  43 => avg_loss: 0.001313\n",
      "#                   Validation loss => 0.018400 | f1: 0.968310 #\n",
      "Epoch  44 => avg_loss: 0.000772\n",
      "#                   Validation loss => 0.018293 | f1: 0.968310 #\n",
      "Epoch  45 => avg_loss: 0.000901\n",
      "#                   Validation loss => 0.017830 | f1: 0.968310 #\n",
      "Epoch  46 => avg_loss: 0.000875\n",
      "#                   Validation loss => 0.018119 | f1: 0.968310 #\n",
      "Epoch  47 => avg_loss: 0.000421\n",
      "#                   Validation loss => 0.018463 | f1: 0.968310 #\n",
      "Epoch  48 => avg_loss: 0.000755\n",
      "#                   Validation loss => 0.018308 | f1: 0.968310 #\n",
      "Epoch  49 => avg_loss: 0.000747\n",
      "#                   Validation loss => 0.018415 | f1: 0.968310 #\n",
      "Epoch  50 => avg_loss: 0.000731\n",
      "#                   Validation loss => 0.018680 | f1: 0.968310 #\n",
      "Epoch  51 => avg_loss: 0.001421\n",
      "#                   Validation loss => 0.018883 | f1: 0.968421 #\n",
      "Epoch  52 => avg_loss: 0.000589\n",
      "#                   Validation loss => 0.019284 | f1: 0.966725 #\n",
      "Epoch  53 => avg_loss: 0.000962\n",
      "#                   Validation loss => 0.018282 | f1: 0.968421 #\n",
      "Epoch  54 => avg_loss: 0.000582\n",
      "#                   Validation loss => 0.017683 | f1: 0.966608 #\n",
      "Epoch  55 => avg_loss: 0.000636\n",
      "#                   Validation loss => 0.017679 | f1: 0.966608 #\n",
      "Epoch  56 => avg_loss: 0.000512\n",
      "#                   Validation loss => 0.017719 | f1: 0.968421 #\n",
      "Epoch  57 => avg_loss: 0.000584\n",
      "#                   Validation loss => 0.017435 | f1: 0.966608 #\n",
      "Epoch  58 => avg_loss: 0.000513\n",
      "#                   Validation loss => 0.017589 | f1: 0.966608 #\n",
      "Epoch  59 => avg_loss: 0.000737\n",
      "#                   Validation loss => 0.018410 | f1: 0.968421 #\n",
      "Epoch  60 => avg_loss: 0.000733\n",
      "#                   Validation loss => 0.018865 | f1: 0.968421 #\n",
      "Epoch  61 => avg_loss: 0.000483\n",
      "#                   Validation loss => 0.018909 | f1: 0.968421 #\n",
      "Epoch  62 => avg_loss: 0.000495\n",
      "#                   Validation loss => 0.018456 | f1: 0.970018 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch  63 => avg_loss: 0.000574\n",
      "#                   Validation loss => 0.018635 | f1: 0.968310 #\n",
      "Epoch  64 => avg_loss: 0.000855\n",
      "#                   Validation loss => 0.018990 | f1: 0.968310 #\n",
      "Epoch  65 => avg_loss: 0.000484\n",
      "#                   Validation loss => 0.018527 | f1: 0.968310 #\n",
      "Epoch  66 => avg_loss: 0.000332\n",
      "#                   Validation loss => 0.018474 | f1: 0.968310 #\n",
      "Epoch  67 => avg_loss: 0.000301\n",
      "#                   Validation loss => 0.018604 | f1: 0.968310 #\n",
      "Epoch  68 => avg_loss: 0.000492\n",
      "#                   Validation loss => 0.018702 | f1: 0.968310 #\n",
      "Epoch  69 => avg_loss: 0.000377\n",
      "#                   Validation loss => 0.018780 | f1: 0.968310 #\n",
      "Epoch  70 => avg_loss: 0.000407\n",
      "#                   Validation loss => 0.018902 | f1: 0.968310 #\n",
      "Epoch  71 => avg_loss: 0.000482\n",
      "#                   Validation loss => 0.019044 | f1: 0.968310 #\n",
      "Epoch  72 => avg_loss: 0.000592\n",
      "#                   Validation loss => 0.019171 | f1: 0.970018 #\n",
      "Epoch  73 => avg_loss: 0.000424\n",
      "#                   Validation loss => 0.019134 | f1: 0.970018 #\n",
      "Epoch  74 => avg_loss: 0.000448\n",
      "#                   Validation loss => 0.018879 | f1: 0.970018 #\n",
      "Epoch  75 => avg_loss: 0.000342\n",
      "#                   Validation loss => 0.018802 | f1: 0.970018 #\n",
      "Epoch  76 => avg_loss: 0.000447\n",
      "#                   Validation loss => 0.018966 | f1: 0.970018 #\n",
      "Epoch  77 => avg_loss: 0.000730\n",
      "#                   Validation loss => 0.019568 | f1: 0.968421 #\n",
      "Epoch  78 => avg_loss: 0.000357\n",
      "#                   Validation loss => 0.019132 | f1: 0.968310 #\n",
      "Epoch  79 => avg_loss: 0.000317\n",
      "#                   Validation loss => 0.018830 | f1: 0.970018 #\n",
      "Epoch  80 => avg_loss: 0.000333\n",
      "#                   Validation loss => 0.018597 | f1: 0.968310 #\n",
      "Epoch  81 => avg_loss: 0.000347\n",
      "#                   Validation loss => 0.018464 | f1: 0.970018 #\n",
      "Epoch  82 => avg_loss: 0.000308\n",
      "#                   Validation loss => 0.018351 | f1: 0.970018 #\n",
      "Epoch  83 => avg_loss: 0.000851\n",
      "#                   Validation loss => 0.019561 | f1: 0.970123 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch  84 => avg_loss: 0.000384\n",
      "#                   Validation loss => 0.019288 | f1: 0.971831 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch  85 => avg_loss: 0.000318\n",
      "#                   Validation loss => 0.019097 | f1: 0.970123 #\n",
      "Epoch  86 => avg_loss: 0.000273\n",
      "#                   Validation loss => 0.019035 | f1: 0.970123 #\n",
      "Epoch  87 => avg_loss: 0.000233\n",
      "#                   Validation loss => 0.019138 | f1: 0.970123 #\n",
      "Epoch  88 => avg_loss: 0.000308\n",
      "#                   Validation loss => 0.019186 | f1: 0.970123 #\n",
      "Epoch  89 => avg_loss: 0.000268\n",
      "#                   Validation loss => 0.019206 | f1: 0.971831 #\n",
      "Epoch  90 => avg_loss: 0.000512\n",
      "#                   Validation loss => 0.018379 | f1: 0.970018 #\n",
      "Epoch  91 => avg_loss: 0.000488\n",
      "#                   Validation loss => 0.018164 | f1: 0.970018 #\n",
      "Epoch  92 => avg_loss: 0.000329\n",
      "#                   Validation loss => 0.018492 | f1: 0.970018 #\n",
      "Epoch  93 => avg_loss: 0.000324\n",
      "#                   Validation loss => 0.018711 | f1: 0.970018 #\n",
      "Epoch  94 => avg_loss: 0.000413\n",
      "#                   Validation loss => 0.018834 | f1: 0.970018 #\n",
      "Epoch  95 => avg_loss: 0.000232\n",
      "#                   Validation loss => 0.018771 | f1: 0.970018 #\n",
      "Epoch  96 => avg_loss: 0.000325\n",
      "#                   Validation loss => 0.018538 | f1: 0.970018 #\n",
      "Epoch  97 => avg_loss: 0.000245\n",
      "#                   Validation loss => 0.018557 | f1: 0.970018 #\n",
      "Epoch  98 => avg_loss: 0.000721\n",
      "#                   Validation loss => 0.020035 | f1: 0.970123 #\n",
      "Epoch  99 => avg_loss: 0.000291\n",
      "#                   Validation loss => 0.019989 | f1: 0.970123 #\n",
      "Epoch 100 => avg_loss: 0.000271\n",
      "#                   Validation loss => 0.019782 | f1: 0.971831 #\n",
      "Epoch 101 => avg_loss: 0.000515\n",
      "#                   Validation loss => 0.019472 | f1: 0.970123 #\n",
      "Epoch 102 => avg_loss: 0.000252\n",
      "#                   Validation loss => 0.019245 | f1: 0.970123 #\n",
      "Epoch 103 => avg_loss: 0.000410\n",
      "#                   Validation loss => 0.019167 | f1: 0.971831 #\n",
      "Epoch 104 => avg_loss: 0.000209\n",
      "#                   Validation loss => 0.019264 | f1: 0.971831 #\n",
      "Epoch 105 => avg_loss: 0.000345\n",
      "#                   Validation loss => 0.019456 | f1: 0.971831 #\n",
      "Epoch 106 => avg_loss: 0.000142\n",
      "#                   Validation loss => 0.019474 | f1: 0.971831 #\n",
      "Epoch 107 => avg_loss: 0.000138\n",
      "#                   Validation loss => 0.019459 | f1: 0.971831 #\n",
      "Epoch 108 => avg_loss: 0.000191\n",
      "#                   Validation loss => 0.019428 | f1: 0.971831 #\n",
      "Epoch 109 => avg_loss: 0.000174\n",
      "#                   Validation loss => 0.019511 | f1: 0.971831 #\n"
     ]
    }
   ],
   "source": [
    "from stud.modelsTests.utils.Trainer_model2_transformer_simple_multilogits import Trainer_model2_transformer_simple_multilogits\n",
    "\n",
    "trainer = Trainer_model2_transformer_simple_multilogits()\n",
    "\n",
    "history = trainer.train(\n",
    "    final_model, optimizer, dataloader_train, dataloader_dev,\n",
    "    epochs=110, device=device,\n",
    "    save_best=True, \n",
    "    min_score=0.95,\n",
    "    save_path_name=os.path.join(model_dir_path, 'model2_weights_transformer_simple_multilogits.pth'),\n",
    "    saved_history=history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': ['West', 'Indian', 'all-rounder', 'Phil', 'Simmons', 'took', 'four', 'for', '38', 'on', 'Friday', 'as', 'Leicestershire', 'beat', 'Somerset', 'by', 'an', 'innings', 'and', '39', 'runs', 'in', 'two', 'days', 'to', 'take', 'over', 'at', 'the', 'head', 'of', 'the', 'county', 'championship', '.'], 'ner_tags': ['O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'text': 'West Indian all-rounder Phil Simmons took four for 38 on Friday as Leicestershire beat Somerset by an innings and 39 runs in two days to take over at the head of the county championship .', 'entities': [{'entity': 'Phil Simmons', 'offset': 24}], 'ner': ['O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n"
     ]
    }
   ],
   "source": [
    "rrrr = final_model.predict(dataset_dev.data_raw[test_idx])\n",
    "print(rrrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Phil Simmons took four for 38 on Friday as Leicestershire beat Somerset by an innings and 39 runs in two days to take over at the head of the county championship .'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rrrr['text'][rrrr['entities'][0]['offset']:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "ex_in_simple = dataset_dev.create_collate_fn()([dataset_dev[test_idx]])\n",
    "predictions = final_model.model(\n",
    "    input_ids = ex_in_simple['input_ids'].to(device), \n",
    "    attention_mask = ex_in_simple['attention_mask'].to(device),\n",
    "    token_type_ids = ex_in_simple['token_type_ids'].to(device),\n",
    ")\n",
    "sample_predictions = final_model.model.get_indices(predictions).detach().cpu().tolist()[0]\n",
    "print(sample_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Andy', 'C', '##ad', '##dick']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.tokenizer.tokenize('Andy Caddick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Andy Caddick'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.tokenizer.decode( \n",
    "    dataset_train.tokenizer.encode('Andy Caddick')[1:-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = Model2(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"The museum announced in late 2004 the selection of Pritzker Prizewinning architect Renzo Piano to design a new addition to the Gardner's campus. The new wing is currently under construction and scheduled to open to the public in early 2012. In addition to her responsibilities at the Isabella Stewart Gardner Museum, Ms. Hawley serves as a trustee on the boards of the Doris Duke Charitable Foundation, Save Venice, Inc., and the Fenway Alliance of Boston. Prior to her appointment to the Gardner, Anne Hawley founded the Cultural Education Collaborative, an organization dedicated to stimulating arts public policy and arts education.\", 'entities': [{'entity': 'P', 'offset': 51}, {'entity': 'Renzo Piano', 'offset': 83}, {'entity': 'Isabella', 'offset': 284}, {'entity': '. Hawley', 'offset': 319}, {'entity': 'Doris Duke', 'offset': 369}, {'entity': 'Anne Hawley', 'offset': 498}], 'ner': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n"
     ]
    }
   ],
   "source": [
    "sample_generated = {\n",
    "    'text': \"The museum announced in late 2004 the selection of Pritzker Prizewinning architect Renzo Piano to design a new addition to the Gardner's campus. The new wing is currently under construction and scheduled to open to the public in early 2012. In addition to her responsibilities at the Isabella Stewart Gardner Museum, Ms. Hawley serves as a trustee on the boards of the Doris Duke Charitable Foundation, Save Venice, Inc., and the Fenway Alliance of Boston. Prior to her appointment to the Gardner, Anne Hawley founded the Cultural Education Collaborative, an organization dedicated to stimulating arts public policy and arts education.\"\n",
    "}\n",
    "\n",
    "resp = test_model.predict(sample_generated)\n",
    "\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nlp2022-hw3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f736fa57697717c80caf738108553872322bbbec02a6cb9049e8f17a4d9a2aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
