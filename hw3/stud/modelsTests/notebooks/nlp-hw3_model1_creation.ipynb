{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fe2040e",
   "metadata": {
    "papermill": {
     "duration": 0.078963,
     "end_time": "2022-03-31T22:14:09.386664",
     "exception": false,
     "start_time": "2022-03-31T22:14:09.307701",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marco/miniconda3/envs/nlp2022-hw3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5424a631",
   "metadata": {
    "papermill": {
     "duration": 0.049244,
     "end_time": "2022-03-31T22:14:12.552634",
     "exception": false,
     "start_time": "2022-03-31T22:14:12.503390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Important paths for the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_root = '../../../../'\n",
    "test_name = 'test3'\n",
    "datasets_path = os.path.join(app_root, 'data')\n",
    "model_dir_path = os.path.join(app_root, 'model', test_name)\n",
    "\n",
    "data_train_path = os.path.join(datasets_path, 'train.tsv')\n",
    "data_dev_path = os.path.join(datasets_path, 'dev.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append('../../../')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bc95ee",
   "metadata": {
    "papermill": {
     "duration": 0.048851,
     "end_time": "2022-03-31T22:14:13.015246",
     "exception": false,
     "start_time": "2022-03-31T22:14:12.966395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Setting the seed for reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 28\n",
    "\n",
    "# random.seed(SEED) # not used\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_params = {\n",
    "    'batch_size': 32,\n",
    "    'PAD_TOKEN': '<pad>',\n",
    "    'UNK_TOKEN': '<unk>',\n",
    "    'transformer_name': \"bert-base-cased\",\n",
    "    'mention_tags': {\n",
    "        'p_open':  '<P>', 'p_close':  '</P>', \n",
    "        'e_open':  '<E>', 'e_close':  '</E>', \n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9214a0",
   "metadata": {
    "papermill": {
     "duration": 0.049393,
     "end_time": "2022-03-31T22:14:13.226777",
     "exception": false,
     "start_time": "2022-03-31T22:14:13.177384",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stud.modelsTests.dataset.PronDataset_transformer_simple import PronDataset_transformer_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = PronDataset_transformer_simple(\n",
    "    data_train_path, \n",
    "    tokenizer = global_params['transformer_name'])\n",
    "\n",
    "dataset_dev = PronDataset_transformer_simple(\n",
    "    data_dev_path, \n",
    "    tokenizer = global_params['transformer_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_params.update({ \n",
    "    'token_embeddings_len': len(dataset_train.tokenizer),\n",
    "    'resize_token_embeddings': False, # ! not used\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(model_dir_path, 'global_params.npy'), global_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=global_params['batch_size'],\n",
    "    collate_fn=dataset_train.create_collate_fn(),\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "dataloader_dev = DataLoader(\n",
    "    dataset_dev,\n",
    "    batch_size=global_params['batch_size'],\n",
    "    collate_fn=dataset_dev.create_collate_fn(),\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in dataloader_dev:\n",
    "    ex_in = e\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'words_ids', 'pronoun_hypotesis_ids', 'possible_pronoun_ids', 'gold_pronoun_id', 'gold_pronoun'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_in.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, 0, 1, 1, 2, 3, 4, 5, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 30, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 43, 43, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 1\n",
    "print(ex_in['words_ids'][idx])\n",
    "ex_in['possible_pronoun_ids'][idx], ex_in['gold_pronoun'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  101, 15182,  1753,  1204,  1108,  1255,  1107, 14805,  3169,  3192,\n",
      "          117,  1498,   119,  1430,  1401,   117,  4367,   117,  1108,   170,\n",
      "         4941, 27892, 27229, 17588,   117,  1105,  1123,  1534,   117,  8821,\n",
      "          117,  1868,   170,  9678,  1402,  1107,   139, 14799,  1633,   132,\n",
      "        15182,  1108,  1147,  1503,  1797,   119,  1153,  1108,  4512,  1120,\n",
      "         2090, 10136,  6943, 19773,  1197,  4808,   112,  1323,   113,  1208,\n",
      "         1804,   114,   117,  1498,   117,  1196,  6546,  1624,   112,   188,\n",
      "         1531,   117,  1498,   119,   102,     0,     0,     0,     0,     0]) torch.Size([32, 134])\n"
     ]
    }
   ],
   "source": [
    "print(ex_in['input_ids'][idx][:80], ex_in['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stud.modelsTests.utils.print_infos import print_summary, display_history, plot_confusion_matrix, print_classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from stud.modelsTests.model_1.model1_transformer_simple_multilogits import Model1\n",
    "import torch.optim as optim\n",
    "\n",
    "loss_function = torch.nn.BCELoss()\n",
    "\n",
    "final_model = Model1(\n",
    "    device = device,\n",
    "    loss_fn = loss_function,\n",
    "    model_load_weights = False,\n",
    "    fine_tune_transformer = True,\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(final_model.model.parameters(), lr=0.0016, momentum=0.9)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_some = False\n",
    "if freeze_some:\n",
    "    unfreeze_word_embeddings = False\n",
    "    unfreeze_transformer_layers = True\n",
    "    unfreeze_from_layer_num = 8\n",
    "    unfreeze_to_layer_num = 99\n",
    "    unfreeze_pooler = True\n",
    "\n",
    "    for name, param in final_model.model.named_parameters():\n",
    "\n",
    "        if name.startswith('transformer_model.embeddings'):\n",
    "            param.requires_grad = unfreeze_word_embeddings\n",
    "\n",
    "        elif name.startswith('transformer_model.encoder.layer'):\n",
    "            layer_num = int(name.split('.')[3])\n",
    "            if layer_num >= unfreeze_from_layer_num and layer_num <= unfreeze_to_layer_num:\n",
    "                param.requires_grad = unfreeze_transformer_layers\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        elif name.startswith('transformer_model.pooler'):\n",
    "            param.requires_grad = unfreeze_pooler\n",
    "        \n",
    "        print(param.requires_grad, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model1_net(\n",
      "  (transformer_model): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (loss_fn): BCELoss()\n",
      ")\n",
      "----------------------\n",
      "parameters: 108,311,041\n",
      "trainable parameters: 108,311,041\n",
      "non-trainable parameters: 0\n"
     ]
    }
   ],
   "source": [
    "print_summary(final_model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[0.4999, 0.5814, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.5166, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.5080, 0.4999, 0.4999, 0.5166, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.5695,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.5334, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999],\n",
      "        [0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.5659, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.5545,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.6161, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999],\n",
      "        [0.4999, 0.4999, 0.6731, 0.4999, 0.4999, 0.6629, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.6503, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.6119,\n",
      "         0.4999, 0.4999, 0.4999, 0.6492, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.5192, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999, 0.4999]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor(0.6978, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    }
   ],
   "source": [
    "ex_in_simple = dataset_dev.create_collate_fn()([dataset_dev[0], dataset_dev[1], dataset_dev[2]])\n",
    "predictions = final_model.model(\n",
    "    input_ids = ex_in_simple['input_ids'].to(device), \n",
    "    attention_mask = ex_in_simple['attention_mask'].to(device),\n",
    "    token_type_ids = ex_in_simple['token_type_ids'].to(device),\n",
    "    predicted_pronouns = ex_in_simple['possible_pronoun_ids'].to(device),\n",
    ")\n",
    "labels = ex_in_simple['gold_pronoun'].to(device)\n",
    "\n",
    "print(labels)\n",
    "print(predictions)\n",
    "print(final_model.model.compute_loss(predictions, labels ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'validation-1', 'text': 'He admitted making four trips to China and playing golf there. He also admitted that ZTE officials, whom he says are his golf buddies, hosted and paid for the trips. Jose de Venecia III, son of House Speaker Jose de Venecia Jr, alleged that Abalos offered him US$10 million to withdraw his proposal on the NBN project.', 'pron': 'He', 'p_offset': 0, 'entity_A': 'Jose de Venecia Jr', 'offset_A': 208, 'is_coref_A': 'FALSE', 'entity_B': 'Abalos', 'offset_B': 241, 'is_coref_B': 'FALSE'}\n"
     ]
    }
   ],
   "source": [
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "print(final_model.predict(dataset_dev.data_raw[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 => avg_loss: 0.006963\n",
      "WARN: there are 23 offset errors, out of 400 correct in 454 total!\n",
      "#               Validation loss => 0.008301 | accuracy: 0.881057 #\n",
      "Epoch   1 => avg_loss: 0.006851\n",
      "WARN: there are 23 offset errors, out of 400 correct in 454 total!\n",
      "#               Validation loss => 0.008229 | accuracy: 0.881057 #\n",
      "Epoch   2 => avg_loss: 0.006748\n",
      "WARN: there are 23 offset errors, out of 400 correct in 454 total!\n",
      "#               Validation loss => 0.008210 | accuracy: 0.881057 #\n",
      "Epoch   3 => avg_loss: 0.006786\n",
      "WARN: there are 23 offset errors, out of 400 correct in 454 total!\n",
      "#               Validation loss => 0.008177 | accuracy: 0.881057 #\n",
      "Epoch   4 => avg_loss: 0.006689\n",
      "WARN: there are 23 offset errors, out of 400 correct in 454 total!\n",
      "#               Validation loss => 0.008131 | accuracy: 0.881057 #\n",
      "Epoch   5 => avg_loss: 0.006673\n",
      "WARN: there are 23 offset errors, out of 400 correct in 454 total!\n",
      "#               Validation loss => 0.008093 | accuracy: 0.881057 #\n",
      "Epoch   6 => avg_loss: 0.006650\n",
      "WARN: there are 23 offset errors, out of 400 correct in 454 total!\n",
      "#               Validation loss => 0.008066 | accuracy: 0.881057 #\n",
      "Epoch   7 => avg_loss: 0.006528\n",
      "WARN: there are 23 offset errors, out of 400 correct in 454 total!\n",
      "#               Validation loss => 0.008029 | accuracy: 0.881057 #\n",
      "Epoch   8 => avg_loss: 0.006563\n",
      "WARN: there are 23 offset errors, out of 400 correct in 454 total!\n",
      "#               Validation loss => 0.007983 | accuracy: 0.881057 #\n",
      "Epoch   9 => avg_loss: 0.006444\n",
      "WARN: there are 23 offset errors, out of 400 correct in 454 total!\n",
      "#               Validation loss => 0.007965 | accuracy: 0.881057 #\n",
      "Epoch  10 => avg_loss: 0.006408\n",
      "WARN: there are 23 offset errors, out of 400 correct in 454 total!\n",
      "#               Validation loss => 0.007941 | accuracy: 0.881057 #\n",
      "Epoch  11 => avg_loss: 0.006487\n",
      "WARN: there are 23 offset errors, out of 400 correct in 454 total!\n",
      "#               Validation loss => 0.007913 | accuracy: 0.881057 #\n",
      "Epoch  12 => avg_loss: 0.006371\n",
      "WARN: there are 23 offset errors, out of 400 correct in 454 total!\n",
      "#               Validation loss => 0.007872 | accuracy: 0.881057 #\n",
      "Epoch  13 => avg_loss: 0.006326\n",
      "WARN: there are 23 offset errors, out of 400 correct in 454 total!\n",
      "#               Validation loss => 0.007856 | accuracy: 0.881057 #\n",
      "Epoch  14 => avg_loss: 0.006316\n",
      "WARN: there are 23 offset errors, out of 400 correct in 454 total!\n",
      "#               Validation loss => 0.007825 | accuracy: 0.881057 #\n",
      "Epoch  15 => avg_loss: 0.006253\n",
      "WARN: there are 23 offset errors, out of 400 correct in 454 total!\n",
      "#               Validation loss => 0.007816 | accuracy: 0.881057 #\n",
      "Epoch  16 => avg_loss: 0.006116\n",
      "WARN: there are 23 offset errors, out of 400 correct in 454 total!\n",
      "#               Validation loss => 0.007765 | accuracy: 0.881057 #\n",
      "Epoch  17 => avg_loss: 0.006156\n",
      "WARN: there are 23 offset errors, out of 403 correct in 454 total!\n",
      "#               Validation loss => 0.007737 | accuracy: 0.887665 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch  18 => avg_loss: 0.006136\n",
      "WARN: there are 23 offset errors, out of 402 correct in 454 total!\n",
      "#               Validation loss => 0.007701 | accuracy: 0.885463 #\n",
      "Epoch  19 => avg_loss: 0.006080\n",
      "WARN: there are 23 offset errors, out of 402 correct in 454 total!\n",
      "#               Validation loss => 0.007686 | accuracy: 0.885463 #\n",
      "Epoch  20 => avg_loss: 0.006117\n",
      "WARN: there are 23 offset errors, out of 402 correct in 454 total!\n",
      "#               Validation loss => 0.007668 | accuracy: 0.885463 #\n",
      "Epoch  21 => avg_loss: 0.006018\n",
      "WARN: there are 23 offset errors, out of 402 correct in 454 total!\n",
      "#               Validation loss => 0.007628 | accuracy: 0.885463 #\n",
      "Epoch  22 => avg_loss: 0.005995\n",
      "WARN: there are 23 offset errors, out of 402 correct in 454 total!\n",
      "#               Validation loss => 0.007607 | accuracy: 0.885463 #\n",
      "Epoch  23 => avg_loss: 0.005929\n",
      "WARN: there are 23 offset errors, out of 402 correct in 454 total!\n",
      "#               Validation loss => 0.007575 | accuracy: 0.885463 #\n",
      "Epoch  24 => avg_loss: 0.005905\n",
      "WARN: there are 23 offset errors, out of 402 correct in 454 total!\n",
      "#               Validation loss => 0.007575 | accuracy: 0.885463 #\n",
      "Epoch  25 => avg_loss: 0.005957\n",
      "WARN: there are 23 offset errors, out of 402 correct in 454 total!\n",
      "#               Validation loss => 0.007534 | accuracy: 0.885463 #\n",
      "Epoch  26 => avg_loss: 0.005848\n",
      "WARN: there are 23 offset errors, out of 402 correct in 454 total!\n",
      "#               Validation loss => 0.007505 | accuracy: 0.885463 #\n",
      "Epoch  27 => avg_loss: 0.005783\n",
      "WARN: there are 23 offset errors, out of 402 correct in 454 total!\n",
      "#               Validation loss => 0.007467 | accuracy: 0.885463 #\n",
      "Epoch  28 => avg_loss: 0.005784\n",
      "WARN: there are 23 offset errors, out of 402 correct in 454 total!\n",
      "#               Validation loss => 0.007469 | accuracy: 0.885463 #\n",
      "Epoch  29 => avg_loss: 0.005723\n",
      "WARN: there are 23 offset errors, out of 402 correct in 454 total!\n",
      "#               Validation loss => 0.007430 | accuracy: 0.885463 #\n",
      "Epoch  30 => avg_loss: 0.005704\n",
      "WARN: there are 23 offset errors, out of 402 correct in 454 total!\n",
      "#               Validation loss => 0.007461 | accuracy: 0.885463 #\n",
      "Epoch  31 => avg_loss: 0.005719\n",
      "WARN: there are 23 offset errors, out of 402 correct in 454 total!\n",
      "#               Validation loss => 0.007378 | accuracy: 0.885463 #\n",
      "Epoch  32 => avg_loss: 0.005565\n",
      "WARN: there are 23 offset errors, out of 403 correct in 454 total!\n",
      "#               Validation loss => 0.007370 | accuracy: 0.887665 #\n",
      "Epoch  33 => avg_loss: 0.005648\n",
      "WARN: there are 23 offset errors, out of 402 correct in 454 total!\n",
      "#               Validation loss => 0.007337 | accuracy: 0.885463 #\n",
      "Epoch  34 => avg_loss: 0.005614\n",
      "WARN: there are 23 offset errors, out of 404 correct in 454 total!\n",
      "#               Validation loss => 0.007318 | accuracy: 0.889868 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch  35 => avg_loss: 0.005493\n",
      "WARN: there are 23 offset errors, out of 402 correct in 454 total!\n",
      "#               Validation loss => 0.007311 | accuracy: 0.885463 #\n",
      "Epoch  36 => avg_loss: 0.005491\n",
      "WARN: there are 23 offset errors, out of 402 correct in 454 total!\n",
      "#               Validation loss => 0.007293 | accuracy: 0.885463 #\n",
      "Epoch  37 => avg_loss: 0.005463\n",
      "WARN: there are 23 offset errors, out of 404 correct in 454 total!\n",
      "#               Validation loss => 0.007274 | accuracy: 0.889868 #\n",
      "Epoch  38 => avg_loss: 0.005441\n",
      "WARN: there are 23 offset errors, out of 404 correct in 454 total!\n",
      "#               Validation loss => 0.007241 | accuracy: 0.889868 #\n",
      "Epoch  39 => avg_loss: 0.005378\n",
      "WARN: there are 23 offset errors, out of 404 correct in 454 total!\n",
      "#               Validation loss => 0.007244 | accuracy: 0.889868 #\n"
     ]
    }
   ],
   "source": [
    "from stud.modelsTests.utils.Trainer_model1_transformer_simple_multilogits import Trainer_model1_transformer_simple_multilogits\n",
    "\n",
    "trainer = Trainer_model1_transformer_simple_multilogits()\n",
    "\n",
    "history = trainer.train(\n",
    "    final_model, optimizer, dataloader_train, dataloader_dev,\n",
    "    epochs=40, device=device,\n",
    "    save_best=True, \n",
    "    min_score=0.6,\n",
    "    save_path_name=os.path.join(model_dir_path, 'model1_weights_transformer_simple_multilogits.pth'),\n",
    "    saved_history=history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "``I know this for a fact that the manager and the players are 100 per cent behind David Dein and I can see real repercussions coming off the back of this.'' http://www.independent.co.uk/sport/football/premier-league/players-upset-by-deins-departure-445419.html%20 Thierry Henry claimed that David Dein's departure as vice-chairman had dismayed him and left him in no doubt that it was time to move on. ['him', 344]\n",
      "['him', 377] 106\n"
     ]
    }
   ],
   "source": [
    "blacklist = []\n",
    "\n",
    "for idxxx in range(len(dataset_dev.data_raw)):\n",
    "    eerrs = final_model.predict(dataset_dev.data_raw[idxxx])\n",
    "    if eerrs['pron'] == dataset_dev.data_raw[idxxx]['pron'] and eerrs['p_offset'] != dataset_dev.data_raw[idxxx]['p_offset'] and idxxx not in blacklist:\n",
    "        print(dataset_dev.data_raw[idxxx]['text'], [dataset_dev.data_raw[idxxx]['pron'], dataset_dev.data_raw[idxxx]['p_offset']])\n",
    "        print([eerrs['pron'], eerrs['p_offset']], idxxx)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' it was time to move on.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"``I know this for a fact that the manager and the players are 100 per cent behind David Dein and I can see real repercussions coming off the back of this.'' http://www.independent.co.uk/sport/football/premier-league/players-upset-by-deins-departure-445419.html%20 Thierry Henry claimed that David Dein's departure as vice-chairman had dismayed him and left him in no doubt that it was time to move on.\"[377:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pron = 'him'\n",
    "regexed = r\"\" + \"\\W(\" + pron + \")\\W\"\n",
    "strdd = \"http://www.independent.co.uk/sport/football/premier-league/players-upset-by-deins-departure-445419.html%20 that him is lol\"\n",
    "resex = re.search(regexed, strdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'him is lol'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strdd[resex.start()+1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stud.modelsTests.model_1.model1_transformer_simple_multilogits import Model1\n",
    "\n",
    "final_model = Model1(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stud.modelsTests.utils.Trainer_model1_transformer_simple_multilogits import Trainer_model1_transformer_simple_multilogits\n",
    "\n",
    "trainer = Trainer_model1_transformer_simple_multilogits()\n",
    "\n",
    "evaluate = trainer.compute_evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for step, sample in enumerate(dataset_dev.data_raw):\n",
    "        predictions.append( final_model.predict(sample) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: there are 23 offset errors, out of 404 correct in 454 total!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8898678414096917}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev_res = evaluate(predictions, dataset_dev.data_raw)\n",
    "ev_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nlp2022-hw3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f736fa57697717c80caf738108553872322bbbec02a6cb9049e8f17a4d9a2aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
