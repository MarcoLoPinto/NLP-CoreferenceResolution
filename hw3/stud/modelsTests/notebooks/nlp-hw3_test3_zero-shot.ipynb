{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marco/miniconda3/envs/nlp2022-hw3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "from stud.modelsTests.utils.print_infos import print_summary, display_history, plot_confusion_matrix, print_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"vasudevgupta/bigbird-roberta-natural-questions\"\n",
    "model_id = \"facebook/bart-large-mnli\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def read_dataset(file_path):\n",
    "    data = []\n",
    "    with open(file_path) as file:\n",
    "        tsv_file = csv.reader(file, delimiter=\"\\t\")\n",
    "        for sample in tsv_file:\n",
    "            if sample[3] == 'Pronoun-offset':\n",
    "                continue\n",
    "            data_row1 = {\n",
    "                'id': sample[0], \n",
    "                'text': sample[1], \n",
    "                'pron': sample[2], 'p_offset': int(sample[3]), \n",
    "                'entity': sample[4], 'offset': int(sample[5]), 'is_coref': sample[6], # candidate 1\n",
    "                # 'url': sample[10], # not useful\n",
    "            }\n",
    "            data_row2 = {\n",
    "                'id': sample[0], \n",
    "                'text': sample[1], \n",
    "                'pron': sample[2], 'p_offset': int(sample[3]), \n",
    "                'entity': sample[7], 'offset': int(sample[8]), 'is_coref': sample[9], # candidate 2\n",
    "                # 'url': sample[10], # not useful\n",
    "            }\n",
    "            data.append(data_row1); data.append(data_row2)\n",
    "    return data\n",
    "\n",
    "data_test = read_dataset('../../../../data/dev.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model_coref(sample):\n",
    "    candidates = [ 'not ' + sample['entity'], sample['entity'] ]\n",
    "    labels, scores = [], []\n",
    "    for label in candidates:\n",
    "        premise = sample['text']\n",
    "        hypothesis = f\"{sample['pron']} is {label}.\"\n",
    "\n",
    "        # run through model pre-trained on MNLI\n",
    "        x = tokenizer.encode(premise, hypothesis, return_tensors='pt',\n",
    "                            truncation_strategy='only_first')\n",
    "        with torch.no_grad():\n",
    "            logits = model(x)[0]\n",
    "\n",
    "        # we throw away \"neutral\" (dim 1) and take the probability of\n",
    "        # \"entailment\" (2) as the probability of the label being true \n",
    "        entail_contradiction_logits = logits[:,[0,2]]\n",
    "        probs = entail_contradiction_logits.softmax(dim=1)\n",
    "        prob_label_is_true = probs[:,1].tolist()[0]\n",
    "\n",
    "        labels.append(label)\n",
    "        scores.append(prob_label_is_true)\n",
    "\n",
    "    return labels, scores\n",
    "\n",
    "def forward(sample):\n",
    "    labels, scores = select_model_coref(sample)\n",
    "    if all(x <= 0.5 for x in scores):\n",
    "        return 0\n",
    "    else:\n",
    "        idx = scores.index( max(scores) )\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'validation-3',\n",
       " 'text': 'When she returns to her hotel room, a Liberian man (Tony Todd) forces her to smuggle $20 million worth of conflict diamonds to New York, or else fellow fight attendant and friend Angela will die. She is caught before she can board the flight, and the team now have nine hours until the plane lands, and save Angela. After the confiscated diamonds are stolen by the brother of Kaleo (Jason Scott Lee), whom Danny put away for murdering his partner last year, Five-0 and Chief Fryer team up and enlist the help of August March (Ed Asner), who served a 30-year sentence for smuggling diamonds.',\n",
       " 'pron': 'his',\n",
       " 'p_offset': 435,\n",
       " 'entity': 'Danny',\n",
       " 'offset': 406,\n",
       " 'is_coref': 'TRUE'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_n = 5\n",
    "data_test[id_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model_coref_multi(data, batch_size = 16):\n",
    "    labels, scores = [], []\n",
    "\n",
    "    premises_inputs, hypothesis_inputs = [], []\n",
    "\n",
    "    for i in range(0,len(data),batch_size):\n",
    "        samples = data[i:i+batch_size]\n",
    "        for sample in samples:\n",
    "            candidates = [ 'not ' + sample['entity'] , sample['entity'] ]\n",
    "            labels.append(candidates)\n",
    "            for label in candidates:\n",
    "                premise = sample['text']\n",
    "                hypothesis = f\"{sample['pron']} is {label}.\"\n",
    "\n",
    "                premises_inputs.append(premise); hypothesis_inputs.append(hypothesis)\n",
    "\n",
    "        # run through model pre-trained on MNLI\n",
    "        x = tokenizer(premises_inputs, hypothesis_inputs, return_tensors='pt', is_split_into_words=False, padding=True)['input_ids']\n",
    "        with torch.no_grad():\n",
    "            logits = model(x)[0]\n",
    "        probs = logits[:,[0,2]].softmax(dim=-1)[:,1]\n",
    "        scores += probs.reshape((probs.shape[0]//2,-1)).tolist()\n",
    "\n",
    "    return labels, scores\n",
    "\n",
    "def forward(samples):\n",
    "    results = []\n",
    "    labels_multi, scores_multi = select_model_coref_multi(samples)\n",
    "    for labels, scores in zip(labels_multi, scores_multi):\n",
    "        res = 0 if all(x <= 0.5 for x in scores) else scores.index( max(scores) )\n",
    "        results.append(res)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/Marco/Desktop/Magistrale/NLP/projects/2022_hw3/nlp2022-hw3/hw3/stud/modelsTests/notebooks/tests copy.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Marco/Desktop/Magistrale/NLP/projects/2022_hw3/nlp2022-hw3/hw3/stud/modelsTests/notebooks/tests%20copy.ipynb#ch0000009vscode-remote?line=0'>1</a>\u001b[0m true_labels \u001b[39m=\u001b[39m [s[\u001b[39m'\u001b[39m\u001b[39mis_coref\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m data_test]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Marco/Desktop/Magistrale/NLP/projects/2022_hw3/nlp2022-hw3/hw3/stud/modelsTests/notebooks/tests%20copy.ipynb#ch0000009vscode-remote?line=1'>2</a>\u001b[0m correctly_predicted \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Marco/Desktop/Magistrale/NLP/projects/2022_hw3/nlp2022-hw3/hw3/stud/modelsTests/notebooks/tests%20copy.ipynb#ch0000009vscode-remote?line=3'>4</a>\u001b[0m labels_multi, scores_multi \u001b[39m=\u001b[39m select_model_coref_multi(data_test)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Marco/Desktop/Magistrale/NLP/projects/2022_hw3/nlp2022-hw3/hw3/stud/modelsTests/notebooks/tests%20copy.ipynb#ch0000009vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m t_label, labels, scores \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(true_labels, labels_multi, scores_multi):\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Marco/Desktop/Magistrale/NLP/projects/2022_hw3/nlp2022-hw3/hw3/stud/modelsTests/notebooks/tests%20copy.ipynb#ch0000009vscode-remote?line=6'>7</a>\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(x \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m scores) \u001b[39melse\u001b[39;00m scores\u001b[39m.\u001b[39mindex( \u001b[39mmax\u001b[39m(scores) )\n",
      "\u001b[1;32m/mnt/c/Users/Marco/Desktop/Magistrale/NLP/projects/2022_hw3/nlp2022-hw3/hw3/stud/modelsTests/notebooks/tests copy.ipynb Cell 9\u001b[0m in \u001b[0;36mselect_model_coref_multi\u001b[0;34m(data, batch_size)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Marco/Desktop/Magistrale/NLP/projects/2022_hw3/nlp2022-hw3/hw3/stud/modelsTests/notebooks/tests%20copy.ipynb#ch0000009vscode-remote?line=17'>18</a>\u001b[0m x \u001b[39m=\u001b[39m tokenizer(premises_inputs, hypothesis_inputs, return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m, is_split_into_words\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, padding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Marco/Desktop/Magistrale/NLP/projects/2022_hw3/nlp2022-hw3/hw3/stud/modelsTests/notebooks/tests%20copy.ipynb#ch0000009vscode-remote?line=18'>19</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Marco/Desktop/Magistrale/NLP/projects/2022_hw3/nlp2022-hw3/hw3/stud/modelsTests/notebooks/tests%20copy.ipynb#ch0000009vscode-remote?line=19'>20</a>\u001b[0m     logits \u001b[39m=\u001b[39m model(x)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Marco/Desktop/Magistrale/NLP/projects/2022_hw3/nlp2022-hw3/hw3/stud/modelsTests/notebooks/tests%20copy.ipynb#ch0000009vscode-remote?line=20'>21</a>\u001b[0m probs \u001b[39m=\u001b[39m logits[:,[\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m]]\u001b[39m.\u001b[39msoftmax(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)[:,\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Marco/Desktop/Magistrale/NLP/projects/2022_hw3/nlp2022-hw3/hw3/stud/modelsTests/notebooks/tests%20copy.ipynb#ch0000009vscode-remote?line=21'>22</a>\u001b[0m scores \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m probs\u001b[39m.\u001b[39mreshape((probs\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp2022-hw3/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp2022-hw3/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:1496\u001b[0m, in \u001b[0;36mBartForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1491\u001b[0m \u001b[39mif\u001b[39;00m input_ids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1492\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1493\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPassing input embeddings is currently not supported for \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1494\u001b[0m     )\n\u001b[0;32m-> 1496\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m   1497\u001b[0m     input_ids,\n\u001b[1;32m   1498\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1499\u001b[0m     decoder_input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   1500\u001b[0m     decoder_attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1501\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1502\u001b[0m     decoder_head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1503\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1504\u001b[0m     encoder_outputs\u001b[39m=\u001b[39;49mencoder_outputs,\n\u001b[1;32m   1505\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1506\u001b[0m     decoder_inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   1507\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1508\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1509\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1510\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1511\u001b[0m )\n\u001b[1;32m   1512\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]  \u001b[39m# last hidden state\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m eos_mask \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39meq(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39meos_token_id)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp2022-hw3/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp2022-hw3/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:1240\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1233\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1234\u001b[0m         last_hidden_state\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m0\u001b[39m],\n\u001b[1;32m   1235\u001b[0m         hidden_states\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m         attentions\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1237\u001b[0m     )\n\u001b[1;32m   1239\u001b[0m \u001b[39m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1240\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[1;32m   1241\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   1242\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1243\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_outputs[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m   1244\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1245\u001b[0m     head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1246\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1247\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1248\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   1249\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1250\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1251\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1252\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1253\u001b[0m )\n\u001b[1;32m   1255\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1256\u001b[0m     \u001b[39mreturn\u001b[39;00m decoder_outputs \u001b[39m+\u001b[39m encoder_outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp2022-hw3/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp2022-hw3/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:1098\u001b[0m, in \u001b[0;36mBartDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m   1087\u001b[0m         create_custom_forward(decoder_layer),\n\u001b[1;32m   1088\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1095\u001b[0m     )\n\u001b[1;32m   1096\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1098\u001b[0m     layer_outputs \u001b[39m=\u001b[39m decoder_layer(\n\u001b[1;32m   1099\u001b[0m         hidden_states,\n\u001b[1;32m   1100\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1101\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1102\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m   1103\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49m(head_mask[idx] \u001b[39mif\u001b[39;49;00m head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1104\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49m(\n\u001b[1;32m   1105\u001b[0m             cross_attn_head_mask[idx] \u001b[39mif\u001b[39;49;00m cross_attn_head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m   1106\u001b[0m         ),\n\u001b[1;32m   1107\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m   1108\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1109\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1110\u001b[0m     )\n\u001b[1;32m   1111\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1113\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp2022-hw3/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp2022-hw3/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:437\u001b[0m, in \u001b[0;36mBartDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[39m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001b[39;00m\n\u001b[1;32m    436\u001b[0m cross_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 437\u001b[0m hidden_states, cross_attn_weights, cross_attn_present_key_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder_attn(\n\u001b[1;32m    438\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    439\u001b[0m     key_value_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    440\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m    441\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[1;32m    442\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mcross_attn_past_key_value,\n\u001b[1;32m    443\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    444\u001b[0m )\n\u001b[1;32m    445\u001b[0m hidden_states \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mdropout(hidden_states, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[1;32m    446\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp2022-hw3/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp2022-hw3/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:282\u001b[0m, in \u001b[0;36mBartAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39m# Use the `embed_dim` from the config (stored in the class) rather than `hidden_state` because `attn_output` can be\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[39m# partitioned aross GPUs when using tensor-parallelism.\u001b[39;00m\n\u001b[1;32m    280\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mreshape(bsz, tgt_len, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim)\n\u001b[0;32m--> 282\u001b[0m attn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj(attn_output)\n\u001b[1;32m    284\u001b[0m \u001b[39mreturn\u001b[39;00m attn_output, attn_weights_reshaped, past_key_value\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp2022-hw3/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp2022-hw3/lib/python3.9/site-packages/torch/nn/modules/linear.py:96\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp2022-hw3/lib/python3.9/site-packages/torch/nn/functional.py:1847\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, weight):\n\u001b[1;32m   1846\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[39minput\u001b[39m, weight), \u001b[39minput\u001b[39m, weight, bias\u001b[39m=\u001b[39mbias)\n\u001b[0;32m-> 1847\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, weight, bias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "true_labels = [1 if s['is_coref']=='TRUE' else 0 for s in data_test]\n",
    "correctly_predicted = 0\n",
    "\n",
    "labels_multi, scores_multi = select_model_coref_multi(data_test)\n",
    "\n",
    "for t_label, labels, scores in zip(true_labels, labels_multi, scores_multi):\n",
    "    res = 0 if all(x <= 0.5 for x in scores) else scores.index( max(scores) )\n",
    "    if res == t_label:\n",
    "        correctly_predicted += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(611, 908, 0.6729074889867841)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p, t = 0, 0\n",
    "for e in data_test:\n",
    "    r = forward(e)\n",
    "    l = 1 if e['is_coref'] == 'TRUE' else 0\n",
    "    if r == l:\n",
    "        p+=1\n",
    "    t+=1\n",
    "p,t, p/t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nlp2022-hw3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f736fa57697717c80caf738108553872322bbbec02a6cb9049e8f17a4d9a2aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
